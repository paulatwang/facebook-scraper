{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7cf499-a04e-4083-8866-9453f95e4814",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb057644-e27b-4b23-8415-d27270e501be",
   "metadata": {},
   "source": [
    "**Picking a scraper package**\n",
    "\n",
    "There are a variety of python packages that are designed to scrape social media posts. Some examples (ranked by number of stars):\n",
    "\n",
    "- [Ultimate Facebook Scraper](https://github.com/harismuneer/Ultimate-Facebook-Scraper) 2.6k stars. Last activity Jul 2023. \"Scrapes almost everything about a Facebook user's profile\". Uses Selenium. Requires $119 payment.\n",
    "- [Unofficial APIs](https://github.com/Rolstenhouse/unofficial-apis) 2.5k stars. Last activity Jan 2023. List of unofficial APIs for various services, none for Facebook for now, but might be worth to check in the future.\n",
    "- [facebook-page-post-scraper](https://github.com/minimaxir/facebook-page-post-scraper) 2.1k stars. Last activity Dec 2017. Archived and read-only. \n",
    "- [facebook-scraper](https://github.com/kevinzg/facebook-scraper) 1.9k stars. Last activity Nov 2023. \"Scrape Facebook public pages without an API key.\"\n",
    "- [facebook-post-scraper](https://github.com/brutalsavage/facebook-post-scraper) 282 stars. Last activity Sep 2020. \"Scrape Facebook Public Posts without using Facebook API.\"\n",
    "- [major-scrapy-spiders](https://github.com/talhashraf/major-scrapy-spiders) 272 stars. Last activity Jul 2017. Has a profile spider for Scrapy.\n",
    "- [facebook-scraper-selenium](https://github.com/apurvmishra99/facebook-scraper-selenium) 179 stars. Last activity Jun 2020. \"Scrape posts from any group or user into a .csv file without needing to register for any API access\".\n",
    "\n",
    "Based on this list, it seems that the highest starred option that isn't paid, is available for Facebook, and isn't archived is `facebook-scraper`. So that is what we will use. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44023eac-b229-411c-b59b-eb160d00dd4d",
   "metadata": {},
   "source": [
    "To use the `facebook-scraper` package, we need cookies to bypass the login page. Export Facebook.com cookies using extension such as [Edit This Cookie](https://www.editthiscookie.com/). Save as txt file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb3f380-3093-43b7-92b8-ff17c2aad3ed",
   "metadata": {},
   "source": [
    "**Picking a sentiment analysis package**\n",
    "\n",
    "For sentiment analysis, there are a few package options:\n",
    "\n",
    "- [NTLK](https://www.nltk.org/) Most comprehensive. Requires configuration and training for sentiment analysis.\n",
    "- [TextBlob](https://textblob.readthedocs.io/en/dev/) Built on NTLK. Pre-trained sentiment analyzer. Composite polarity score.\n",
    "- [VADER](https://github.com/cjhutto/vaderSentiment) Built on NTLK. Particularly strong for short-form text like article headlines and social media. Proportional pos/neg/neu and composite score.\n",
    "- [spaCy](https://spacy.io/usage) Offers pretrained models and tools for NLP.\n",
    "- [Transformers](https://huggingface.co/docs/transformers/index) Offers pretrained models for a variety of NLP tasks.\n",
    "\n",
    "We will use VADER."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe6003b-b8d8-4641-87a5-5ef9eda40d7b",
   "metadata": {},
   "source": [
    "**Setting up conda environment**\n",
    "\n",
    "Set up a conda environment with the following specifications:\n",
    "```\n",
    "name: scraper\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python==3.8\n",
    "  - jupyterlab==4.0.8\n",
    "  - ipykernel==6.25.0\n",
    "  - numpy==1.24.4\n",
    "  - pandas==2.0.3\n",
    "  - matplotlib==3.7.3\n",
    "  - seaborn==0.13.0\n",
    "  - beautifulsoup4==4.12.2\n",
    "  - requests==2.31.0\n",
    "  - pip==23.3.1 \n",
    "  - pip:\n",
    "    - nltk==3.8.1\n",
    "    - facebook-scraper==0.2.59\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25254651-ee5d-4782-9d5f-63f069476101",
   "metadata": {},
   "source": [
    "# Facebook Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670dde43-8157-4d15-bdf4-c2b890f85f71",
   "metadata": {},
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cc239bd-e380-40bd-85ea-0ab32634eb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulawang/opt/miniconda3/envs/scraper/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from facebook_scraper import get_posts\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c0699-7f10-4914-a870-260777767e34",
   "metadata": {},
   "source": [
    "Get posts, including comments and reactors. Running it directly (rather than writing it into a function) allows the `listposts` variable to add some post data even after temporarily banning happens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b61c468d-471c-49e1-92d5-fb72e37a39a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TemporarilyBanned",
     "evalue": "You‚Äôre Temporarily Blocked",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTemporarilyBanned\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m listposts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m post \u001b[38;5;129;01min\u001b[39;00m get_posts(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnews.com.au\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      6\u001b[0m                       cookies\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcookies.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m                       pages\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      8\u001b[0m                       options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomments\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreactors\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposts_per_page\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m}):\n\u001b[1;32m      9\u001b[0m     listposts\u001b[38;5;241m.\u001b[39mappend(post)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/scraper/lib/python3.8/site-packages/facebook_scraper/facebook_scraper.py:1117\u001b[0m, in \u001b[0;36mFacebookScraper._generic_get_posts\u001b[0;34m(self, extract_post_fn, iter_pages_fn, page_limit, options, remove_source, latest_date, max_past_limit, **kwargs)\u001b[0m\n\u001b[1;32m   1115\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting posts from page \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, i)\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m post_element \u001b[38;5;129;01min\u001b[39;00m page:\n\u001b[0;32m-> 1117\u001b[0m     post \u001b[38;5;241m=\u001b[39m \u001b[43mextract_post_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpost_element\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remove_source:\n\u001b[1;32m   1119\u001b[0m         post\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/scraper/lib/python3.8/site-packages/facebook_scraper/extractors.py:33\u001b[0m, in \u001b[0;36mextract_post\u001b[0;34m(raw_post, options, request_fn, full_post_html)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_post\u001b[39m(\n\u001b[1;32m     31\u001b[0m     raw_post: RawPost, options: Options, request_fn: RequestFunction, full_post_html\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     32\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Post:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPostExtractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_post\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_post_html\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/scraper/lib/python3.8/site-packages/facebook_scraper/extractors.py:193\u001b[0m, in \u001b[0;36mPostExtractor.extract_post\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m methods:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 193\u001b[0m         partial_post \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m partial_post \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m             log_warning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract method \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt return anything\u001b[39m\u001b[38;5;124m\"\u001b[39m, method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/scraper/lib/python3.8/site-packages/facebook_scraper/extractors.py:947\u001b[0m, in \u001b[0;36mPostExtractor.extract_video_meta\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_video_meta\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 947\u001b[0m     elem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_post_html\u001b[49m\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscript[type=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/ld+json\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m, first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m elem:\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/scraper/lib/python3.8/site-packages/facebook_scraper/extractors.py:1351\u001b[0m, in \u001b[0;36mPostExtractor.full_post_html\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1349\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1351\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mNotFound \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1353\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost_url\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(FB_BASE_URL, FB_MOBILE_BASE_URL)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/scraper/lib/python3.8/site-packages/facebook_scraper/facebook_scraper.py:929\u001b[0m, in \u001b[0;36mFacebookScraper.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedResponse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour request couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be processed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m title\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m temp_ban_titles:\n\u001b[0;32m--> 929\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTemporarilyBanned(title\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>your account has been disabled<\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39mhtml\u001b[38;5;241m.\u001b[39mlower():\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mAccountDisabled(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour Account Has Been Disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTemporarilyBanned\u001b[0m: You‚Äôre Temporarily Blocked"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "listposts = []\n",
    "for post in get_posts(\"news.com.au\", \n",
    "                      cookies=\"cookies.txt\",\n",
    "                      pages=100,\n",
    "                      options={\"comments\":True, \"reactors\": True, \"posts_per_page\": 10}):\n",
    "    listposts.append(post)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94521ee2-f4f2-4372-a07d-0eab329b3fa0",
   "metadata": {},
   "source": [
    "Export raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c192ee3-2c6c-413c-84d5-5992de9bc939",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.DataFrame.from_dict(listposts)\n",
    "# raw.to_csv(\"fb_data4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9746a1f7-cbf8-4730-baaa-21928586318a",
   "metadata": {},
   "source": [
    "One of the issues with running the get_posts() function is the possibility of getting temporarily blocked by Facebook, which has happened everytime. The block seems to last anywhere between a few hours to a few days. Potential remedies:\n",
    "\n",
    "- Create a delay between requests. Don't think `facebook-scraper` offers an option for this.\n",
    "- Rotate IPs. Perhaps via VPN or Tor.\n",
    "- Randomize user-agents. Perhaps via `requests`, `Selenium`, or manually switch browser. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28288a90-91ec-4ccc-aa5f-9ace6e5c57f4",
   "metadata": {},
   "source": [
    "Because of the issues with blocking, I have several separately scraped raw data files. We can collate them below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dac4306-20f5-47cd-aadc-874b6f1e7e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total posts: 260\n"
     ]
    }
   ],
   "source": [
    "raw1 = pd.read_csv(\"fb_data1.csv\")\n",
    "raw2 = pd.read_csv(\"fb_data2.csv\")\n",
    "raw3 = pd.read_csv(\"fb_data3.csv\")\n",
    "raw4 = pd.read_csv(\"fb_data4.csv\")\n",
    "raw_collated = pd.DataFrame()\n",
    "\n",
    "for files in [raw1, raw2, raw3, raw4]:\n",
    "    raw_collated = pd.concat([raw_collated, files])\n",
    "\n",
    "print(f\"Number of total posts: {len(raw_collated)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a56fe0b-9e85-4163-94f8-3b1062bd1fbd",
   "metadata": {},
   "source": [
    "Drop duplicate posts (same `post_id`). Keep the one with greater number of reactions (`reaction_count`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc570f0a-d70f-4f1a-8b85-015338cde57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts: 182\n",
      "Number of columns: 54\n"
     ]
    }
   ],
   "source": [
    "raw_collated = raw_collated.sort_values(\"reaction_count\", ascending=False).groupby(\"post_id\").head(1)\n",
    "raw_collated = raw_collated.sort_values(\"time\", ascending=False).reset_index()\n",
    "\n",
    "print(f\"Number of posts: {len(raw_collated)}\")\n",
    "print(f\"Number of columns: {raw_collated.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c437b63f-dad2-472d-a9fb-b0d2d5f46eef",
   "metadata": {},
   "source": [
    "# Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bed6d5-f59b-49af-8744-4d5bb24d2568",
   "metadata": {},
   "source": [
    "Let's take a look at the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea1f098f-2b00-402b-aa64-21d9a2b62c82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 182 entries, 0 to 181\n",
      "Data columns (total 54 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   index                          182 non-null    int64  \n",
      " 1   Unnamed: 0                     182 non-null    int64  \n",
      " 2   post_id                        182 non-null    int64  \n",
      " 3   text                           182 non-null    object \n",
      " 4   post_text                      182 non-null    object \n",
      " 5   shared_text                    134 non-null    object \n",
      " 6   original_text                  0 non-null      float64\n",
      " 7   time                           182 non-null    object \n",
      " 8   timestamp                      182 non-null    int64  \n",
      " 9   image                          31 non-null     object \n",
      " 10  image_lowquality               151 non-null    object \n",
      " 11  images                         151 non-null    object \n",
      " 12  images_description             151 non-null    object \n",
      " 13  images_lowquality              151 non-null    object \n",
      " 14  images_lowquality_description  151 non-null    object \n",
      " 15  video                          17 non-null     object \n",
      " 16  video_duration_seconds         0 non-null      float64\n",
      " 17  video_height                   0 non-null      float64\n",
      " 18  video_id                       17 non-null     float64\n",
      " 19  video_quality                  0 non-null      float64\n",
      " 20  video_size_MB                  0 non-null      float64\n",
      " 21  video_thumbnail                17 non-null     object \n",
      " 22  video_watches                  0 non-null      float64\n",
      " 23  video_width                    0 non-null      float64\n",
      " 24  likes                          182 non-null    float64\n",
      " 25  comments                       182 non-null    int64  \n",
      " 26  shares                         182 non-null    int64  \n",
      " 27  post_url                       182 non-null    object \n",
      " 28  link                           136 non-null    object \n",
      " 29  links                          151 non-null    object \n",
      " 30  user_id                        182 non-null    int64  \n",
      " 31  username                       151 non-null    object \n",
      " 32  user_url                       151 non-null    object \n",
      " 33  is_live                        182 non-null    bool   \n",
      " 34  factcheck                      0 non-null      float64\n",
      " 35  shared_post_id                 2 non-null      float64\n",
      " 36  shared_time                    2 non-null      object \n",
      " 37  shared_user_id                 2 non-null      float64\n",
      " 38  shared_username                2 non-null      object \n",
      " 39  shared_post_url                2 non-null      object \n",
      " 40  available                      182 non-null    bool   \n",
      " 41  comments_full                  182 non-null    object \n",
      " 42  reactors                       61 non-null     object \n",
      " 43  w3_fb_url                      61 non-null     object \n",
      " 44  reactions                      61 non-null     object \n",
      " 45  reaction_count                 182 non-null    int64  \n",
      " 46  with                           2 non-null      object \n",
      " 47  page_id                        182 non-null    int64  \n",
      " 48  sharers                        0 non-null      float64\n",
      " 49  image_id                       31 non-null     float64\n",
      " 50  image_ids                      151 non-null    object \n",
      " 51  was_live                       182 non-null    bool   \n",
      " 52  fetched_time                   61 non-null     object \n",
      " 53  header                         2 non-null      object \n",
      "dtypes: bool(3), float64(14), int64(9), object(28)\n",
      "memory usage: 73.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df = raw_collated.copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b156b75e-6f42-43d6-859c-aea6cf17f6cc",
   "metadata": {},
   "source": [
    "Some initial thoughts:\n",
    "\n",
    "- All posts come with a caption (`post_text`)\n",
    "- Most, but not all posts share a link (`link`)\n",
    "- A few posts come with an image (`image`)\n",
    "- Only a few posts come with a video (`video`)\n",
    "\n",
    "It looks like total posts = posts with links + posts with video. So maybe all posts without links are video posts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd2fc4e-9d47-4b1c-b4f7-cf77ffa77041",
   "metadata": {},
   "source": [
    "The package scrapes a good amount of data for each post, 51 columns in total. We don't need all of it, so we can select only the columns that we need for exploration, cleaning, and analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdbc7835-127e-41ea-a690-8966d20db712",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"post_id\", #unique id\n",
    "           \"post_text\", #caption\n",
    "           \"time\", \n",
    "           \"video\", \n",
    "           \"image\",\n",
    "           \"likes\",\n",
    "           \"comments\",\n",
    "           \"shares\",\n",
    "           \"link\",\n",
    "           \"reaction_count\",\n",
    "]\n",
    "\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223f3800-bb10-4228-94a5-bbd54c0d5140",
   "metadata": {},
   "source": [
    "To start, let's look at which posts don't have links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55a8a8c5-7703-472e-91c6-14b4d1918d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts without links:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 46 entries, 0 to 176\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   post_id         46 non-null     int64  \n",
      " 1   post_text       46 non-null     object \n",
      " 2   time            46 non-null     object \n",
      " 3   video           17 non-null     object \n",
      " 4   image           0 non-null      object \n",
      " 5   likes           46 non-null     float64\n",
      " 6   comments        46 non-null     int64  \n",
      " 7   shares          46 non-null     int64  \n",
      " 8   link            0 non-null      object \n",
      " 9   reaction_count  46 non-null     int64  \n",
      "dtypes: float64(1), int64(4), object(5)\n",
      "memory usage: 4.0+ KB\n",
      "None\n",
      "Posts with links:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 136 entries, 31 to 181\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   post_id         136 non-null    int64  \n",
      " 1   post_text       136 non-null    object \n",
      " 2   time            136 non-null    object \n",
      " 3   video           0 non-null      object \n",
      " 4   image           31 non-null     object \n",
      " 5   likes           136 non-null    float64\n",
      " 6   comments        136 non-null    int64  \n",
      " 7   shares          136 non-null    int64  \n",
      " 8   link            136 non-null    object \n",
      " 9   reaction_count  136 non-null    int64  \n",
      "dtypes: float64(1), int64(4), object(5)\n",
      "memory usage: 11.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Posts without links:\")\n",
    "print(df[df.link.isna()].info())\n",
    "print(\"Posts with links:\")\n",
    "print(df[~df.link.isna()].info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56e0307-5747-4abb-aaa4-94504fc1ae05",
   "metadata": {},
   "source": [
    "OK it looks like all posts without links are video posts. Image posts can have links. Let's drop the posts without links. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d4e6dcb-3126-4c5e-b08e-3c6c8d450ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_text</th>\n",
       "      <th>time</th>\n",
       "      <th>video</th>\n",
       "      <th>image</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>shares</th>\n",
       "      <th>link</th>\n",
       "      <th>reaction_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>759361192893859</td>\n",
       "      <td>‚ÄúHe was probably right! That would‚Äôve changed ...</td>\n",
       "      <td>2023-11-07 18:40:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>759348716228440</td>\n",
       "      <td>This is one way to steal the spotlight. üëÄ</td>\n",
       "      <td>2023-11-07 18:20:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>759338512896127</td>\n",
       "      <td>COMMENT: The Melbourne Cup might be seen as a ...</td>\n",
       "      <td>2023-11-07 18:00:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>759332346230077</td>\n",
       "      <td>Stargazers should enjoy Saturn‚Äôs rings while t...</td>\n",
       "      <td>2023-11-07 17:40:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>759326902897288</td>\n",
       "      <td>What an iconic Aussie collaboration!</td>\n",
       "      <td>2023-11-07 17:20:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           post_id                                          post_text  \\\n",
       "0  759361192893859  ‚ÄúHe was probably right! That would‚Äôve changed ...   \n",
       "1  759348716228440          This is one way to steal the spotlight. üëÄ   \n",
       "2  759338512896127  COMMENT: The Melbourne Cup might be seen as a ...   \n",
       "3  759332346230077  Stargazers should enjoy Saturn‚Äôs rings while t...   \n",
       "4  759326902897288               What an iconic Aussie collaboration!   \n",
       "\n",
       "                  time video image  likes  comments  shares link  \\\n",
       "0  2023-11-07 18:40:02   NaN   NaN    2.0         0       0  NaN   \n",
       "1  2023-11-07 18:20:01   NaN   NaN    3.0         7       0  NaN   \n",
       "2  2023-11-07 18:00:01   NaN   NaN   26.0        96       1  NaN   \n",
       "3  2023-11-07 17:40:01   NaN   NaN   16.0         3       0  NaN   \n",
       "4  2023-11-07 17:20:02   NaN   NaN   13.0         2       0  NaN   \n",
       "\n",
       "   reaction_count  \n",
       "0               2  \n",
       "1               5  \n",
       "2              60  \n",
       "3              17  \n",
       "4              13  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28676b0-5272-4132-9330-29f29eda2d6c",
   "metadata": {},
   "source": [
    "Looking at the data, the scraper does a generally good job and there isn't too much to clean manually. I did some manual eyeballing of the `post_text` against the Facebook.com/news.com.au page and everything looks good. The only few cleaning steps we need to do are:\n",
    "\n",
    "- Remove the posts without links\n",
    "- Remove the video and image columns\n",
    "- Rename 'post_text' to 'caption'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2674d592-a4d4-4149-bc53-57502db802b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136 entries, 0 to 135\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   index           136 non-null    int64  \n",
      " 1   post_id         136 non-null    int64  \n",
      " 2   caption         136 non-null    object \n",
      " 3   time            136 non-null    object \n",
      " 4   likes           136 non-null    float64\n",
      " 5   comments        136 non-null    int64  \n",
      " 6   shares          136 non-null    int64  \n",
      " 7   link            136 non-null    object \n",
      " 8   reaction_count  136 non-null    int64  \n",
      "dtypes: float64(1), int64(5), object(3)\n",
      "memory usage: 9.7+ KB\n",
      "Number of posts: 136\n",
      "Number of columns: 9\n"
     ]
    }
   ],
   "source": [
    "df = df[~df.link.isna()].reset_index()\n",
    "df.drop(['video','image'], axis=1, inplace=True)\n",
    "df.rename({\"post_text\":\"caption\"}, axis=1, inplace=True)\n",
    "df.info()\n",
    "print(f\"Number of posts: {len(df)}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a9b375-ed6e-4506-9969-599a01b241c1",
   "metadata": {},
   "source": [
    "# Scrape Article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e380b908-31f2-43d0-97aa-d42f22359228",
   "metadata": {},
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49d1886f-28a2-4c3b-8af6-11b821f29d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc7198b-b153-41b3-8fdb-0d92076474ac",
   "metadata": {},
   "source": [
    "This function needs to be customized based on the HTML setup of the individual website. For news.com.au, headlines are found under h1 class, id=\"story-headline\". Articles are found under div class, id=\"story-primary\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07df08ee-9265-4c7e-94fc-0df9d8ca8465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200: # HTTP status code 200 = successful request\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        title = soup.find('h1', id=\"story-headline\").get_text()\n",
    "        article = soup.find('div', id=\"story-primary\").get_text()\n",
    "        \n",
    "        return title, article\n",
    "        \n",
    "    else:\n",
    "        print(f\"Page unreachable for {url}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "871ac7df-2ce3-44be-a4ed-62bc12474645",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = df.link.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cca874d-788d-4078-951a-7330031b9ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data = [get_article(link) for link in links]\n",
    "article_text = [data[1] for data in article_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9bfc00-c6e5-419f-a0a0-5f253c61ade9",
   "metadata": {},
   "source": [
    "To make sure that the article was pulled correctly, we can check that the article text doesn't contain any strings less than 1000 characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cce2b7f-b470-4f5c-bd98-d8cabf9e12c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in article_text if len(s) < 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e154a8c-ad7e-41c1-9f22-b778c10203f6",
   "metadata": {},
   "source": [
    "Add article_data to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccaf2036-793f-42ff-b644-51d87e3d28b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Melbourne Cup Carnival 2023: Martha Kalifatidi...</td>\n",
       "      <td>Martha Kalifatidis joined in the merriment at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Home &amp; Away star shares diagnosis after cruel ...</td>\n",
       "      <td>Home &amp; Away star Kyle Shilling seemingly felt ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>New details of the victims of the Daylesford b...</td>\n",
       "      <td>A heart breaking picture has emerged of the fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>The devastating song that left everyone in tea...</td>\n",
       "      <td>Matthew Perry‚Äôs family and friends were in tea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Melbourne Cup form guide 2023: Every horse rat...</td>\n",
       "      <td>The full field for the 2023 Melbourne Cup has ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         article_title  \\\n",
       "94   Melbourne Cup Carnival 2023: Martha Kalifatidi...   \n",
       "115  Home & Away star shares diagnosis after cruel ...   \n",
       "54   New details of the victims of the Daylesford b...   \n",
       "87   The devastating song that left everyone in tea...   \n",
       "95   Melbourne Cup form guide 2023: Every horse rat...   \n",
       "\n",
       "                                          article_text  \n",
       "94   Martha Kalifatidis joined in the merriment at ...  \n",
       "115  Home & Away star Kyle Shilling seemingly felt ...  \n",
       "54   A heart breaking picture has emerged of the fa...  \n",
       "87   Matthew Perry‚Äôs family and friends were in tea...  \n",
       "95   The full field for the 2023 Melbourne Cup has ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_data_df = pd.DataFrame(article_data, columns=[\"article_title\", \"article_text\"])\n",
    "article_data_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8265f4b-bb52-4139-a17d-ab38a1d22a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>post_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>time</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>shares</th>\n",
       "      <th>link</th>\n",
       "      <th>reaction_count</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>55</td>\n",
       "      <td>758623186300993</td>\n",
       "      <td>Just in time for your summer barbecue üåû</td>\n",
       "      <td>2023-11-06 14:00:02</td>\n",
       "      <td>88.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.news.com.au/finance/business/retai...</td>\n",
       "      <td>93</td>\n",
       "      <td>Why expensive supermarket item is now cheap ‚Äì ...</td>\n",
       "      <td>Australia‚Äôs sheep population has reached an al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42</td>\n",
       "      <td>758702379626407</td>\n",
       "      <td>OPINION: The Melbourne Cup is now the race tha...</td>\n",
       "      <td>2023-11-06 18:20:01</td>\n",
       "      <td>202.0</td>\n",
       "      <td>443</td>\n",
       "      <td>9</td>\n",
       "      <td>https://www.news.com.au/sport/superracing/melb...</td>\n",
       "      <td>344</td>\n",
       "      <td>‚ÄòWorld has changed‚Äô: Why Aussies aren‚Äôt headin...</td>\n",
       "      <td>OPINIONThe Melbourne Cup is not just one of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>67</td>\n",
       "      <td>758320876331224</td>\n",
       "      <td>He's revealed some behind-the-scenes drama wen...</td>\n",
       "      <td>2023-11-06 04:20:01</td>\n",
       "      <td>77.0</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>https://bit.ly/40olRVw?fbclid=IwAR1mpoqqJIHkAK...</td>\n",
       "      <td>77</td>\n",
       "      <td>Dave Hughes reveals massive Block auction error</td>\n",
       "      <td>Dave Hughes was a surprise attendee at this ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>128</td>\n",
       "      <td>757742429722402</td>\n",
       "      <td>\"They would probably claim a moral victory.\"</td>\n",
       "      <td>2023-11-05 03:40:02</td>\n",
       "      <td>689.0</td>\n",
       "      <td>117</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.news.com.au/sport/cricket/starc-de...</td>\n",
       "      <td>689</td>\n",
       "      <td>Starc destroys England with cheeky ‚Äòmoral vict...</td>\n",
       "      <td>Mitchell Starc couldn‚Äôt help but take a light-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>157</td>\n",
       "      <td>756984033131575</td>\n",
       "      <td>No zooper doopers were harmed in the incident. üç¶</td>\n",
       "      <td>2023-11-03 16:40:01</td>\n",
       "      <td>34.0</td>\n",
       "      <td>206</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.news.com.au/lifestyle/food/eat/col...</td>\n",
       "      <td>34</td>\n",
       "      <td>Coles defends 25 cent paper bags after custome...</td>\n",
       "      <td>A major supermarket has defended its paper bag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index          post_id  \\\n",
       "20      55  758623186300993   \n",
       "9       42  758702379626407   \n",
       "31      67  758320876331224   \n",
       "84     128  757742429722402   \n",
       "112    157  756984033131575   \n",
       "\n",
       "                                               caption                 time  \\\n",
       "20             Just in time for your summer barbecue üåû  2023-11-06 14:00:02   \n",
       "9    OPINION: The Melbourne Cup is now the race tha...  2023-11-06 18:20:01   \n",
       "31   He's revealed some behind-the-scenes drama wen...  2023-11-06 04:20:01   \n",
       "84        \"They would probably claim a moral victory.\"  2023-11-05 03:40:02   \n",
       "112   No zooper doopers were harmed in the incident. üç¶  2023-11-03 16:40:01   \n",
       "\n",
       "     likes  comments  shares  \\\n",
       "20    88.0        13       0   \n",
       "9    202.0       443       9   \n",
       "31    77.0       107       1   \n",
       "84   689.0       117       7   \n",
       "112   34.0       206       3   \n",
       "\n",
       "                                                  link  reaction_count  \\\n",
       "20   https://www.news.com.au/finance/business/retai...              93   \n",
       "9    https://www.news.com.au/sport/superracing/melb...             344   \n",
       "31   https://bit.ly/40olRVw?fbclid=IwAR1mpoqqJIHkAK...              77   \n",
       "84   https://www.news.com.au/sport/cricket/starc-de...             689   \n",
       "112  https://www.news.com.au/lifestyle/food/eat/col...              34   \n",
       "\n",
       "                                         article_title  \\\n",
       "20   Why expensive supermarket item is now cheap ‚Äì ...   \n",
       "9    ‚ÄòWorld has changed‚Äô: Why Aussies aren‚Äôt headin...   \n",
       "31     Dave Hughes reveals massive Block auction error   \n",
       "84   Starc destroys England with cheeky ‚Äòmoral vict...   \n",
       "112  Coles defends 25 cent paper bags after custome...   \n",
       "\n",
       "                                          article_text  \n",
       "20   Australia‚Äôs sheep population has reached an al...  \n",
       "9    OPINIONThe Melbourne Cup is not just one of th...  \n",
       "31   Dave Hughes was a surprise attendee at this ye...  \n",
       "84   Mitchell Starc couldn‚Äôt help but take a light-...  \n",
       "112  A major supermarket has defended its paper bag...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2 = pd.concat([df2,article_data_df], axis=1)\n",
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ba5d10-a863-4789-8f08-3006703ab453",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91865b75-1250-42ec-9ad1-9f385b7177fb",
   "metadata": {},
   "source": [
    "VADER polarity scores (pos, neu, neg) are ratios for proportions of text that fall in each category. The compound score  (com) is the sum of the valence for each word, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4228e7e2-8178-43e6-bb8c-a6dcb8c23670",
   "metadata": {},
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36560bc0-484d-4a9f-9ea7-d3cb8fd95a0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2480c32-f54c-4079-8870-736382431b65",
   "metadata": {},
   "source": [
    "Functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a985cb81-7f1b-469a-85e2-0fcf1789b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analyzer(text):\n",
    "    d = {'neg':analyzer.polarity_scores(text)['neg'],\n",
    "         'neu':analyzer.polarity_scores(text)['neu'],\n",
    "         'pos':analyzer.polarity_scores(text)['pos'],\n",
    "         'com':analyzer.polarity_scores(text)['compound']}\n",
    "    return d\n",
    "\n",
    "def add_sentiments_to_df(df, colnames):\n",
    "    for col in colnames:\n",
    "        sentiments = df[col].apply(lambda x: sentiment_analyzer(x)).apply(pd.Series)\n",
    "        sentiments.columns = [col+\"_neg\", \n",
    "                              col+\"_neu\",\n",
    "                              col+\"_pos\", \n",
    "                              col+\"_com\"]\n",
    "        df = pd.concat([df, sentiments], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237e9093-d50d-4fef-9b27-753948fd5379",
   "metadata": {},
   "source": [
    "Add sentiments for whichever text you want to conduct sentiment analysis on. (Options: article_text, article_title, post_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "833bcc3e-88ff-4d6e-9847-ed7e7fe610b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "df3 = add_sentiments_to_df(df3, [\"article_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bede95c3-f72f-424f-8a22-499057b0633d",
   "metadata": {},
   "source": [
    "Export data to csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4809b6e-818a-404c-b4c9-f54cd2033a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136 entries, 0 to 135\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   index             136 non-null    int64  \n",
      " 1   post_id           136 non-null    int64  \n",
      " 2   caption           136 non-null    object \n",
      " 3   time              136 non-null    object \n",
      " 4   likes             136 non-null    float64\n",
      " 5   comments          136 non-null    int64  \n",
      " 6   shares            136 non-null    int64  \n",
      " 7   link              136 non-null    object \n",
      " 8   reaction_count    136 non-null    int64  \n",
      " 9   article_title     136 non-null    object \n",
      " 10  article_text      136 non-null    object \n",
      " 11  article_text_neg  136 non-null    float64\n",
      " 12  article_text_neu  136 non-null    float64\n",
      " 13  article_text_pos  136 non-null    float64\n",
      " 14  article_text_com  136 non-null    float64\n",
      "dtypes: float64(5), int64(5), object(5)\n",
      "memory usage: 16.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3830224f-b666-45d1-bbd7-de9d524d863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(\"datafile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3923179-7a8f-4fa9-880d-c07a4f1f1742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (scraper)",
   "language": "python",
   "name": "scraper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
